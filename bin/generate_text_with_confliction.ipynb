{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasha/anaconda3/envs/HRI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 98554,\n",
       " 65786,\n",
       " 258,\n",
       " 259,\n",
       " 261,\n",
       " 33029,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 65809,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 33049,\n",
       " 287,\n",
       " 288,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 33067,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 33076,\n",
       " 309,\n",
       " 311,\n",
       " 312,\n",
       " 315,\n",
       " 316,\n",
       " 318,\n",
       " 320,\n",
       " 321,\n",
       " 98625,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 33092,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 33099,\n",
       " 333,\n",
       " 336,\n",
       " 337,\n",
       " 339,\n",
       " 342,\n",
       " 343,\n",
       " 33110,\n",
       " 347,\n",
       " 33115,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 33131,\n",
       " 364,\n",
       " 363,\n",
       " 365,\n",
       " 367,\n",
       " 33134,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 380,\n",
       " 383,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 33156,\n",
       " 33159,\n",
       " 393,\n",
       " 392,\n",
       " 98697,\n",
       " 391,\n",
       " 395,\n",
       " 398,\n",
       " 396,\n",
       " 400,\n",
       " 65930,\n",
       " 402,\n",
       " 33166,\n",
       " 404,\n",
       " 65937,\n",
       " 403,\n",
       " 408,\n",
       " 409,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 33179,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 420,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 65965,\n",
       " 430,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 441,\n",
       " 444,\n",
       " 445,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 451,\n",
       " 452,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 459,\n",
       " 461,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 471,\n",
       " 66007,\n",
       " 473,\n",
       " 472,\n",
       " 33240,\n",
       " 474,\n",
       " 477,\n",
       " 33246,\n",
       " 478,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 488,\n",
       " 491,\n",
       " 492,\n",
       " 496,\n",
       " 497,\n",
       " 499,\n",
       " 501,\n",
       " 502,\n",
       " 505,\n",
       " 33274,\n",
       " 507,\n",
       " 508,\n",
       " 510,\n",
       " 511,\n",
       " 33282,\n",
       " 519,\n",
       " 520,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 533,\n",
       " 535,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 543,\n",
       " 544,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 33327,\n",
       " 560,\n",
       " 561,\n",
       " 33331,\n",
       " 564,\n",
       " 566,\n",
       " 568,\n",
       " 569,\n",
       " 33337,\n",
       " 571,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 584,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 592,\n",
       " 593,\n",
       " 596,\n",
       " 598,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 616,\n",
       " 617,\n",
       " 66154,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 33392,\n",
       " 626,\n",
       " 627,\n",
       " 66163,\n",
       " 631,\n",
       " 98936,\n",
       " 635,\n",
       " 636,\n",
       " 638,\n",
       " 66177,\n",
       " 644,\n",
       " 645,\n",
       " 33413,\n",
       " 646,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 664,\n",
       " 668,\n",
       " 669,\n",
       " 672,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 679,\n",
       " 680,\n",
       " 682,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 33455,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 697,\n",
       " 698,\n",
       " 700,\n",
       " 704,\n",
       " 706,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 713,\n",
       " 716,\n",
       " 717,\n",
       " 719,\n",
       " 720,\n",
       " 722,\n",
       " 723,\n",
       " 66262,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 726,\n",
       " 731,\n",
       " 733,\n",
       " 735,\n",
       " 99040,\n",
       " 743,\n",
       " 749,\n",
       " 751,\n",
       " 752,\n",
       " 754,\n",
       " 755,\n",
       " 757,\n",
       " 758,\n",
       " 99066,\n",
       " 763,\n",
       " 764,\n",
       " 766,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 773,\n",
       " 774,\n",
       " 777,\n",
       " 779,\n",
       " 66318,\n",
       " 783,\n",
       " 782,\n",
       " 785,\n",
       " 788,\n",
       " 33557,\n",
       " 791,\n",
       " 797,\n",
       " 800,\n",
       " 801,\n",
       " 805,\n",
       " 806,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 824,\n",
       " 826,\n",
       " 831,\n",
       " 832,\n",
       " 66370,\n",
       " 836,\n",
       " 66372,\n",
       " 839,\n",
       " 842,\n",
       " 845,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 853,\n",
       " 856,\n",
       " 858,\n",
       " 859,\n",
       " 66396,\n",
       " 861,\n",
       " 864,\n",
       " 867,\n",
       " 868,\n",
       " 33639,\n",
       " 872,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 33642,\n",
       " 880,\n",
       " 883,\n",
       " 884,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 66432,\n",
       " 899,\n",
       " 901,\n",
       " 902,\n",
       " 904,\n",
       " 906,\n",
       " 33678,\n",
       " 911,\n",
       " 912,\n",
       " 910,\n",
       " 914,\n",
       " 918,\n",
       " 919,\n",
       " 921,\n",
       " 922,\n",
       " 66457,\n",
       " 33691,\n",
       " 926,\n",
       " 927,\n",
       " 33697,\n",
       " 931,\n",
       " 66467,\n",
       " 936,\n",
       " 99241,\n",
       " 939,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 950,\n",
       " 33721,\n",
       " 959,\n",
       " 961,\n",
       " 964,\n",
       " 966,\n",
       " 969,\n",
       " 33737,\n",
       " 971,\n",
       " 972,\n",
       " 974,\n",
       " 975,\n",
       " 66511,\n",
       " 977,\n",
       " 978,\n",
       " 66513,\n",
       " 980,\n",
       " 982,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 993,\n",
       " 994,\n",
       " 99299,\n",
       " 998,\n",
       " 1002,\n",
       " 1003,\n",
       " 1005,\n",
       " 1009,\n",
       " 1010,\n",
       " 33780,\n",
       " 1012,\n",
       " 1016,\n",
       " 33787,\n",
       " 1022,\n",
       " 1023,\n",
       " 99328,\n",
       " 1027,\n",
       " 33796,\n",
       " 1030,\n",
       " 1032,\n",
       " 1034,\n",
       " 1036,\n",
       " 1037,\n",
       " 1039,\n",
       " 1041,\n",
       " 33813,\n",
       " 1047,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1053,\n",
       " 1056,\n",
       " 1058,\n",
       " 1060,\n",
       " 1063,\n",
       " 1065,\n",
       " 1067,\n",
       " 99372,\n",
       " 1070,\n",
       " 1071,\n",
       " 33839,\n",
       " 1073,\n",
       " 1074,\n",
       " 1077,\n",
       " 1080,\n",
       " 66616,\n",
       " 33849,\n",
       " 1082,\n",
       " 1083,\n",
       " 1088,\n",
       " 32781,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1098,\n",
       " 1101,\n",
       " 1102,\n",
       " 33871,\n",
       " 1105,\n",
       " 1107,\n",
       " 1109,\n",
       " 33877,\n",
       " 1110,\n",
       " 1113,\n",
       " 1114,\n",
       " 1115,\n",
       " 33885,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1124,\n",
       " 33894,\n",
       " 1127,\n",
       " 1128,\n",
       " 1132,\n",
       " 1135,\n",
       " 1136,\n",
       " 1138,\n",
       " 1139,\n",
       " 1141,\n",
       " 1146,\n",
       " 1147,\n",
       " 1148,\n",
       " 1157,\n",
       " 1160,\n",
       " 1162,\n",
       " 1163,\n",
       " 33936,\n",
       " 1169,\n",
       " 1171,\n",
       " 1174,\n",
       " 1176,\n",
       " 1178,\n",
       " 33947,\n",
       " 66714,\n",
       " 1183,\n",
       " 1187,\n",
       " 1189,\n",
       " 1193,\n",
       " 1195,\n",
       " 1197,\n",
       " 1199,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1207,\n",
       " 1212,\n",
       " 1213,\n",
       " 1215,\n",
       " 1216,\n",
       " 66754,\n",
       " 33987,\n",
       " 1220,\n",
       " 33991,\n",
       " 1223,\n",
       " 1225,\n",
       " 1226,\n",
       " 66761,\n",
       " 1228,\n",
       " 1229,\n",
       " 1233,\n",
       " 1234,\n",
       " 34004,\n",
       " 1243,\n",
       " 1244,\n",
       " 1245,\n",
       " 34013,\n",
       " 34015,\n",
       " 1251,\n",
       " 1253,\n",
       " 1255,\n",
       " 1257,\n",
       " 1259,\n",
       " 1260,\n",
       " 1263,\n",
       " 1268,\n",
       " 1271,\n",
       " 1272,\n",
       " 1274,\n",
       " 34042,\n",
       " 66815,\n",
       " 1283,\n",
       " 1284,\n",
       " 1285,\n",
       " 34055,\n",
       " 1288,\n",
       " 1291,\n",
       " 1292,\n",
       " 1295,\n",
       " 1303,\n",
       " 1304,\n",
       " 99608,\n",
       " 1306,\n",
       " 1305,\n",
       " 1311,\n",
       " 1313,\n",
       " 1314,\n",
       " 34081,\n",
       " 32826,\n",
       " 1317,\n",
       " 1315,\n",
       " 1316,\n",
       " 32827,\n",
       " 34090,\n",
       " 1326,\n",
       " 1331,\n",
       " 1334,\n",
       " 1335,\n",
       " 1336,\n",
       " 1337,\n",
       " 34107,\n",
       " 66875,\n",
       " 1342,\n",
       " 1345,\n",
       " 1347,\n",
       " 34117,\n",
       " 1354,\n",
       " 1355,\n",
       " 34124,\n",
       " 1360,\n",
       " 1364,\n",
       " 1371,\n",
       " 34139,\n",
       " 34142,\n",
       " 66911,\n",
       " 1376,\n",
       " 1374,\n",
       " 1382,\n",
       " 1383,\n",
       " 1386,\n",
       " 1387,\n",
       " 1389,\n",
       " 1395,\n",
       " 1396,\n",
       " 1399,\n",
       " 1403,\n",
       " 1405,\n",
       " 1409,\n",
       " 1413,\n",
       " 1414,\n",
       " 1418,\n",
       " 1419,\n",
       " 1425,\n",
       " 1428,\n",
       " 1430,\n",
       " 1435,\n",
       " 1436,\n",
       " 32851,\n",
       " 1443,\n",
       " 1445,\n",
       " 1450,\n",
       " 1451,\n",
       " 1453,\n",
       " 1455,\n",
       " 99759,\n",
       " 1457,\n",
       " 1458,\n",
       " 1461,\n",
       " 1463,\n",
       " 1472,\n",
       " 34242,\n",
       " 1475,\n",
       " 1481,\n",
       " 1486,\n",
       " 1490,\n",
       " 1494,\n",
       " 34263,\n",
       " 1496,\n",
       " 1501,\n",
       " 1503,\n",
       " 1505,\n",
       " 1508,\n",
       " 1511,\n",
       " 1514,\n",
       " 1517,\n",
       " 1518,\n",
       " 1520,\n",
       " 1521,\n",
       " 1523,\n",
       " 1524,\n",
       " 1527,\n",
       " 1531,\n",
       " 1534,\n",
       " 1540,\n",
       " 1542,\n",
       " 1543,\n",
       " 1544,\n",
       " 34311,\n",
       " 1548,\n",
       " 1549,\n",
       " 1550,\n",
       " 1552,\n",
       " 1553,\n",
       " 1555,\n",
       " 1556,\n",
       " 1557,\n",
       " 34326,\n",
       " 1559,\n",
       " 1561,\n",
       " 67098,\n",
       " 1565,\n",
       " 1566,\n",
       " 1567,\n",
       " 32876,\n",
       " 1568,\n",
       " 1570,\n",
       " 99878,\n",
       " 99881,\n",
       " 1578,\n",
       " 1579,\n",
       " 1584,\n",
       " 1587,\n",
       " 1591,\n",
       " 1593,\n",
       " 1594,\n",
       " 1597,\n",
       " 1601,\n",
       " 1603,\n",
       " ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pickle\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList, LogitsProcessor\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True  # 8비트 양자화 설정\n",
    ")\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             quantization_config=quantization_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 사용할 어휘 집합 정의\n",
    "\n",
    "\n",
    "with open('final_target.pkl', 'rb') as f:\n",
    "    final_target = pickle.load(f)\n",
    "\n",
    "allowed_token_ids = list(final_target)\n",
    "allowed_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLogitsProcessor(LogitsProcessor):\n",
    "    def __call__(self, input_ids, scores):\n",
    "        mask = torch.full_like(scores, 1)\n",
    "        mask[:, allowed_token_ids] = 1.0\n",
    "        return scores * mask \n",
    "\n",
    "# 텍스트 생성 함수\n",
    "def generate_text(input_text, max_length=50):\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    logits_processor = LogitsProcessorList([CustomLogitsProcessor()])\n",
    "    output = model.generate(input_ids, max_length=max_length, logits_processor=logits_processor, temperature = 0.3,)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2024-05-24 14:55:14.822558: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 14:55:14.844272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-24 14:55:14.844292: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-24 14:55:14.845178: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-24 14:55:14.849480: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-24 14:55:15.242372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Explanation of theory of general relativity in 2 sentences: 1. According to the theory of general relativity, gravity is not a force that acts between objects, but rather a curvature of spacetime caused by the presence of mass and energy. 2. The curvature of spacetime around a massive object such as a star or a black hole is what we experience as gravity, and it is this curvature that determines the motion of objects in the vicinity of the object. Explanation of theory of'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Explanation of theory of general relativity in 2 sentences: \", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLogitsProcessor(LogitsProcessor):\n",
    "    def __call__(self, input_ids, scores):\n",
    "        mask = torch.full_like(scores, -float('inf'))\n",
    "        mask[:, allowed_token_ids] = 0\n",
    "        return scores + mask \n",
    "\n",
    "# 텍스트 생성 함수\n",
    "def generate_text(input_text, max_length=50):\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    logits_processor = LogitsProcessorList([CustomLogitsProcessor()])\n",
    "    output = model.generate(input_ids, max_length=max_length, logits_processor=logits_processor, temperature = 0.3,)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Explanation of theory of general relativity in 2 sentences: 1. The general\\nrelatvity is a part of the modern\\nphysics that was developed by\\nAlberth Ei\\nnstei\\nn in the early 20th century. It is a\\ntheo\\nry that\\ndes\\nc\\nr\\nib\\nes\\nthe\\nbeh\\nav\\ni\\nor\\nof\\ngr\\nav\\nit\\ny\\nand\\nthe\\nw'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Explanation of theory of general relativity in 2 sentences: \", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLogitsProcessor(LogitsProcessor):\n",
    "    def __call__(self, input_ids, scores):\n",
    "        mask = torch.full_like(scores, 1)\n",
    "        mask[:, allowed_token_ids] = 2\n",
    "        return scores * mask \n",
    "\n",
    "# 텍스트 생성 함수\n",
    "def generate_text(input_text, max_length=50):\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    logits_processor = LogitsProcessorList([CustomLogitsProcessor()])\n",
    "    output = model.generate(input_ids, max_length=max_length, logits_processor=logits_processor, temperature = 0.3,)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Explanation of theory of general relativity in 2 sentences: 1. The general\\nrela tive\\ntheo\\nry\\nof\\nAl\\nber\\nt\\nEi\\nn\\nst\\ne\\ni\\nn\\n(1915) is a\\ntheo\\nry\\nof\\ng\\nra\\nvi\\nty\\nthat\\ndes\\ncr\\ni\\nbes\\nthe\\nin\\nter\\nac\\nti\\non\\nbe\\ntw\\nee\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Explanation of theory of general relativity in 2 sentences: \", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLogitsProcessor(LogitsProcessor):\n",
    "    def __call__(self, input_ids, scores):\n",
    "        mask = torch.full_like(scores, 1)\n",
    "        mask[:, allowed_token_ids] = 1.1\n",
    "        return scores * mask \n",
    "\n",
    "# 텍스트 생성 함수\n",
    "def generate_text(input_text, max_length=50):\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    logits_processor = LogitsProcessorList([CustomLogitsProcessor()])\n",
    "    output = model.generate(input_ids, max_length=max_length, logits_processor=logits_processor, temperature = 0.3,)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Explanation of theory of general relativity in 2 sentences: 1. The theory of general relativity, developed by Albert Einstein, states that the curvature of spacetime is caused by the presence of mass and energy. 2. According to this theory, the more massive the object, the more it warps the fabric of spacetime around it, and the more it affects the motion of other objects in its vicinity.\\nWhat is the main idea of general relativity? The main idea of'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Explanation of theory of general relativity in 2 sentences: \", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HRI-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
